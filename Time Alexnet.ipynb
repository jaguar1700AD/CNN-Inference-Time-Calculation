{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import  torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "imagenet_data = torchvision.datasets.CIFAR10('D:\\\\datasets\\\\', download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(imagenet_data, batch_size=256, shuffle = False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modifiedAlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(modifiedAlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        time_arr = []\n",
    "        deb_arr = []\n",
    "        global device\n",
    "        \n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                \n",
    "                if device == torch.device('cpu'):\n",
    "                    start = time.time()\n",
    "                    x = layer(x)\n",
    "                    end = time.time()\n",
    "                    time_arr.append((end - start) * 1000)\n",
    "                else:\n",
    "                    start = torch.cuda.Event(enable_timing=True)\n",
    "                    end = torch.cuda.Event(enable_timing=True)\n",
    "                    start.record()\n",
    "                    x = layer(x)\n",
    "                    end.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    time_arr.append(start.elapsed_time(end))\n",
    "                    \n",
    "            else:\n",
    "                #start = time.time()\n",
    "                x = layer(x)\n",
    "                #end = time.time()\n",
    "                #deb_arr.append(end - start)\n",
    "        \n",
    "        #start = time.time()\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        #end = time.time()\n",
    "        #end_time = end - start\n",
    "        \n",
    "        #return x, np.array(time_arr), np.array(deb_arr), end_time\n",
    "        return x, np.array(time_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\shash/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_wts = copy.deepcopy(alexnet.state_dict())\n",
    "model = modifiedAlexNet()\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.hub import load_state_dict_from_url\n",
    "#model_urls = {'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'}\n",
    "#state_dict = load_state_dict_from_url(model_urls['alexnet'])\n",
    "#model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.0002\n",
      "[676.29500961 442.94495869 412.3839035  484.58086205 340.92236614]\n",
      "[16.90737524 11.07362397 10.30959759 12.11452155  8.52305915]\n",
      "Total time taken = 23.85256266593933 seconds\n",
      "Avg End to End = 307.99945373535155 ms\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    if isinstance(model, modifiedAlexNet):\n",
    "        tot_times = np.zeros(5)\n",
    "        #deb_times = np.zeros(8)\n",
    "        #end_times = 0\n",
    "    corrects = 0\n",
    "    done = 0\n",
    "\n",
    "    end_to_end_time = 0.0\n",
    "\n",
    "    with torch.autograd.profiler.profile(use_cuda = (device == torch.device('cuda'))) as prof:\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            start_main = torch.cuda.Event(enable_timing=True)\n",
    "            end_main = torch.cuda.Event(enable_timing=True)\n",
    "            start_main.record()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            done += 1\n",
    "            if done * len(inputs) >= 10000:\n",
    "                break\n",
    "            print(done * len(inputs), end = '\\r')\n",
    "\n",
    "            if isinstance(model, modifiedAlexNet):\n",
    "                #outputs, exec_times, hid_times, end_time = model(inputs)\n",
    "                outputs, exec_times = model(inputs)\n",
    "                tot_times += exec_times\n",
    "                #deb_times += hid_times\n",
    "                #end_times += end_time\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "\n",
    "            end_main.record()\n",
    "            torch.cuda.synchronize()\n",
    "            end_to_end_time += start_main.elapsed_time(end_main)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = corrects.double() / (done * len(inputs))\n",
    "    print('Acc: {:.4f}'.format(acc))\n",
    "\n",
    "    if isinstance(model, modifiedAlexNet):\n",
    "        print(tot_times)\n",
    "        #print(deb_times)\n",
    "        #print(end_times)\n",
    "        tot_times = tot_times / done\n",
    "        print(tot_times)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total time taken = {} seconds'.format(time_elapsed))\n",
    "\n",
    "    end_to_end_time = end_to_end_time / (done)\n",
    "    print('Avg End to End = {} ms'.format(end_to_end_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Name                         Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  \n",
      "---------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "random_                      0.00%            18.500us         0.00%            18.500us         18.500us         0.00%            1.000us          1.000us          1                \n",
      "is_floating_point            0.00%            5.200us          0.00%            5.200us          5.200us          0.00%            2.000us          2.000us          1                \n",
      "is_complex                   0.00%            2.300us          0.00%            2.300us          2.300us          0.00%            1.000us          1.000us          1                \n",
      "item                         0.00%            6.500us          0.00%            13.100us         13.100us         0.00%            4.000us          4.000us          1                \n",
      "_local_scalar_dense          0.00%            6.600us          0.00%            6.600us          6.600us          0.00%            2.000us          2.000us          1                \n",
      "to                           96.55%           7.310s           96.69%           7.320s           45.748ms         48.02%           10.071s          62.943ms         160              \n",
      "detach_                      0.00%            276.100us        0.00%            276.100us        3.451us          0.00%            91.000us         1.137us          80               \n",
      "set_                         0.01%            737.400us        0.01%            737.400us        9.218us          0.00%            92.000us         1.150us          80               \n",
      "empty                        0.13%            9.996ms          0.13%            9.996ms          124.949us        0.52%            109.823ms        1.373ms          80               \n",
      "conv2d                       0.11%            8.091ms          1.38%            104.405ms        535.409us        11.18%           2.344s           12.023ms         195              \n",
      "convolution                  0.10%            7.495ms          1.27%            96.314ms         493.916us        11.14%           2.337s           11.984ms         195              \n",
      "_convolution                 0.17%            12.778ms         1.17%            88.819ms         455.479us        11.12%           2.332s           11.958ms         195              \n",
      "contiguous                   0.10%            7.808ms          0.10%            7.808ms          40.039us         0.05%            9.773ms          50.118us         195              \n",
      "cudnn_convolution            0.90%            68.233ms         0.90%            68.233ms         349.911us        10.96%           2.299s           11.792ms         195              \n",
      "relu_                        0.62%            46.563ms         0.62%            46.563ms         170.560us        1.31%            274.431ms        1.005ms          273              \n",
      "max_pool2d                   0.07%            5.362ms          0.44%            33.152ms         283.349us        1.24%            259.629ms        2.219ms          117              \n",
      "max_pool2d_with_indices      0.37%            27.789ms         0.37%            27.789ms         237.517us        1.18%            248.013ms        2.120ms          117              \n",
      "adaptive_avg_pool2d          0.02%            1.610ms          0.10%            7.446ms          190.931us        0.52%            109.344ms        2.804ms          39               \n",
      "_adaptive_avg_pool2d         0.08%            5.836ms          0.08%            5.836ms          149.646us        0.50%            105.485ms        2.705ms          39               \n",
      "flatten                      0.02%            1.883ms          0.04%            3.166ms          81.167us         0.00%            638.000us        16.359us         39               \n",
      "reshape                      0.01%            479.600us        0.02%            1.283ms          32.892us         0.00%            151.000us        3.872us          39               \n",
      "as_strided                   0.01%            803.200us        0.01%            803.200us        20.595us         0.00%            44.000us         1.128us          39               \n",
      "dropout                      0.04%            2.987ms          0.04%            2.987ms          38.291us         0.01%            2.846ms          36.487us         78               \n",
      "t                            0.03%            2.340ms          0.03%            2.340ms          19.997us         0.00%            155.000us        1.325us          117              \n",
      "addmm                        0.28%            21.016ms         0.28%            21.016ms         179.622us        1.93%            404.104ms        3.454ms          117              \n",
      "max                          0.15%            11.190ms         0.15%            11.190ms         286.921us        0.08%            16.409ms         420.744us        39               \n",
      "eq                           0.09%            6.907ms          0.09%            6.907ms          177.092us        0.03%            6.251ms          160.282us        39               \n",
      "sum                          0.10%            7.685ms          0.10%            7.685ms          197.062us        0.04%            9.205ms          236.026us        39               \n",
      "add                          0.00%            160.700us        0.00%            160.700us        160.700us        0.01%            1.497ms          1.497ms          1                \n",
      "add_                         0.04%            2.785ms          0.04%            2.785ms          73.300us         0.15%            30.558ms         804.158us        38               \n",
      "---------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Self CPU time total: 7.571s\n",
      "CUDA time total: 20.972s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11455.3642578125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.elapsed_time(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
